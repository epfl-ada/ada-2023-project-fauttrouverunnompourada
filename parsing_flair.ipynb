{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary parsing using Flair & Classification of our characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to:\n",
    "- cycle through all summaries in the `plot_summaries.txt` file and count the number of occurences of each character name inside\n",
    "- use this data to classify the characters present inside of the `character.metadata.tsv` file into three categories:\n",
    "    - **Primary:** the character name takes up over 10% of all mentioned characters\n",
    "    - **Secondary:** the character name takes up less than 10% of all mentioned characters\n",
    "    - **Missed:** the character name is not mentioned in the movie summary at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import missingno as msno\n",
    "from geopy.geocoders import Nominatim\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import pycountry_convert as pc\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dataframes as RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-12 15:40:28,272 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "from flair.nn import Classifier\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Load the model\n",
    "tagger = Classifier.load('ner-fast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `extract_character_names_flair` takes a string (which can be one of the summaries) and goes through all the words inside. If the word is considered a name, then it is appended to a list. The list of names is returned at the end of the function.\n",
    "\n",
    "The function `count_appearances` takes a large string (it can be the summary) and a list of strings (it can be the list of characters found with the first function), and counts the number of times all strings in the list appear in the large text. The function returns a dictionary with the strings from the list and their occurence count inside of the large text.\n",
    "\n",
    "These two functions will be used in the following way for all summaries:\n",
    "- Use `extract_character_names_flair` to identify all character names inside\n",
    "- Use `count_appearances` to count the number of appearances of all character names in the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_character_names_flair(summary):\n",
    "    # Create a Flair Sentence\n",
    "    sentence = Sentence(summary)\n",
    "\n",
    "    # Run NER on the sentence\n",
    "    tagger.predict(sentence)\n",
    "\n",
    "    # Extract character names (NER tags labeled as PER, indicating a person)\n",
    "    character_names = []\n",
    "\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        if entity.tag == 'PER':\n",
    "            character_names.append(entity.text)\n",
    "\n",
    "    return character_names\n",
    "\n",
    "def count_appearances(larger_string, string_list):\n",
    "    # Initialize an empty dictionary to store counts\n",
    "    appearances_dict = {}\n",
    "\n",
    "    # Iterate over each string in the list\n",
    "    for search_string in string_list:\n",
    "        # Count occurrences using the count() method (we convert to lowercase to avoid missing any occurence)\n",
    "        count = larger_string.lower().count(search_string.lower())\n",
    "        \n",
    "        # Store the count in the dictionary\n",
    "        appearances_dict[search_string] = count\n",
    "\n",
    "    return appearances_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us import the summary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wiki ID</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Wiki ID                                            Summary\n",
       "0  23890098  Shlykov, a hard-working taxi driver and Lyosha...\n",
       "1  31186339  The nation of Panem consists of a wealthy Capi...\n",
       "2  20663735  Poovalli Induchoodan  is sentenced for six yea...\n",
       "3   2231378  The Lemon Drop Kid , a New York City swindler,...\n",
       "4    595909  Seventh-day Adventist Church pastor Michael Ch..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = RAW.summaries.copy()\n",
    "summaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the two functions mentionned above to cycle through all summaries and create the character appearance dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Grab a subset of the data (it takes about 8h for 10,000 summaries)\n",
    "sub_summaries = summaries.iloc[:10, :].copy()\n",
    "\n",
    "parsing_results = []\n",
    "\n",
    "for index, row in sub_summaries.iterrows():\n",
    "    # Print the index to keep track of where we are in the parsing\n",
    "    print(index)\n",
    "\n",
    "    # Extract the names from the summary\n",
    "    names = set(extract_character_names_flair(row['Summary']))\n",
    "\n",
    "    # Count the appearances of every name\n",
    "    counts = count_appearances(row['Summary'], names)\n",
    "\n",
    "    # Append the dictionary to the result list\n",
    "    parsing_results.append(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list `parsing_results` will now contain all the dictionaries from the character counting. In order to have a better wiew of the distribution of the characters in each movie summary, we can rank the dictionaries in descending order (to get the most common names at the beginning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsing_results = [\n",
    "    {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "    for d in parsing_results\n",
    "]\n",
    "\n",
    "sub_summaries['Characters'] = parsing_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the resulting dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wiki ID</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23890098</td>\n",
       "      <td>Shlykov, a hard-working taxi driver and Lyosha...</td>\n",
       "      <td>{'Shlykov': 1, 'Lyosha': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31186339</td>\n",
       "      <td>The nation of Panem consists of a wealthy Capi...</td>\n",
       "      <td>{'Katniss': 24, 'Peeta': 16, 'Rue': 11, 'Cato'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20663735</td>\n",
       "      <td>Poovalli Induchoodan  is sentenced for six yea...</td>\n",
       "      <td>{'Induchoodan': 18, 'Menon': 12, 'Manapally': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2231378</td>\n",
       "      <td>The Lemon Drop Kid , a New York City swindler,...</td>\n",
       "      <td>{'Kid': 35, 'Charley': 18, 'Moran': 8, 'Nellie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595909</td>\n",
       "      <td>Seventh-day Adventist Church pastor Michael Ch...</td>\n",
       "      <td>{'Lindy': 7, 'Michael': 4, 'Azaria': 4, 'Chamb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5272176</td>\n",
       "      <td>The president is on his way to give a speech. ...</td>\n",
       "      <td>{'Thomas': 17, 'Baldwin': 7, 'Kate': 5, 'Steve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1952976</td>\n",
       "      <td>{{plot}} The film opens in 1974, as a young gi...</td>\n",
       "      <td>{'Dahlia': 21, 'Cecilia': 19, 'Natasha': 12, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24225279</td>\n",
       "      <td>The story begins with Hannah, a young Jewish t...</td>\n",
       "      <td>{'Hannah': 15, 'Dominic': 14, 'Miss Lombardo':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2462689</td>\n",
       "      <td>Infuriated at being told to write one final co...</td>\n",
       "      <td>{'Doe': 12, 'John Doe': 10, 'Mitchell': 8, 'Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20532852</td>\n",
       "      <td>A line of people  drool at the window of the s...</td>\n",
       "      <td>{'Buzz': 5, 'Woody': 4}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Wiki ID                                            Summary   \n",
       "0  23890098  Shlykov, a hard-working taxi driver and Lyosha...  \\\n",
       "1  31186339  The nation of Panem consists of a wealthy Capi...   \n",
       "2  20663735  Poovalli Induchoodan  is sentenced for six yea...   \n",
       "3   2231378  The Lemon Drop Kid , a New York City swindler,...   \n",
       "4    595909  Seventh-day Adventist Church pastor Michael Ch...   \n",
       "5   5272176  The president is on his way to give a speech. ...   \n",
       "6   1952976  {{plot}} The film opens in 1974, as a young gi...   \n",
       "7  24225279  The story begins with Hannah, a young Jewish t...   \n",
       "8   2462689  Infuriated at being told to write one final co...   \n",
       "9  20532852  A line of people  drool at the window of the s...   \n",
       "\n",
       "                                          Characters  \n",
       "0                        {'Shlykov': 1, 'Lyosha': 1}  \n",
       "1  {'Katniss': 24, 'Peeta': 16, 'Rue': 11, 'Cato'...  \n",
       "2  {'Induchoodan': 18, 'Menon': 12, 'Manapally': ...  \n",
       "3  {'Kid': 35, 'Charley': 18, 'Moran': 8, 'Nellie...  \n",
       "4  {'Lindy': 7, 'Michael': 4, 'Azaria': 4, 'Chamb...  \n",
       "5  {'Thomas': 17, 'Baldwin': 7, 'Kate': 5, 'Steve...  \n",
       "6  {'Dahlia': 21, 'Cecilia': 19, 'Natasha': 12, '...  \n",
       "7  {'Hannah': 15, 'Dominic': 14, 'Miss Lombardo':...  \n",
       "8  {'Doe': 12, 'John Doe': 10, 'Mitchell': 8, 'Wi...  \n",
       "9                            {'Buzz': 5, 'Woody': 4}  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_summaries.to_csv('parsing_15000_19999.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the goal is to classify all characters from the character data into three roles: Primary, Secondary and Missed (explained earlier). First, let us import the data and add a `Role` column (filled with NaN values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wiki ID</th>\n",
       "      <th>Freebase ID</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Character name</th>\n",
       "      <th>Actor DOB</th>\n",
       "      <th>Actor gender</th>\n",
       "      <th>Actor height</th>\n",
       "      <th>Actor ethnicity</th>\n",
       "      <th>Actor name</th>\n",
       "      <th>Actor age at release</th>\n",
       "      <th>Map ID</th>\n",
       "      <th>Character ID</th>\n",
       "      <th>Actor ID</th>\n",
       "      <th>Role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.780</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Desolation Williams</td>\n",
       "      <td>1969-06-15</td>\n",
       "      <td>M</td>\n",
       "      <td>1.727</td>\n",
       "      <td>/m/0x67</td>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>32.0</td>\n",
       "      <td>/m/0jys3g</td>\n",
       "      <td>/m/0bgchn_</td>\n",
       "      <td>/m/01vw26l</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Sgt Jericho Butler</td>\n",
       "      <td>1967-09-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason Statham</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/02vchl6</td>\n",
       "      <td>/m/0bgchnq</td>\n",
       "      <td>/m/034hyc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Bashira Kincaid</td>\n",
       "      <td>1977-09-25</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clea DuVall</td>\n",
       "      <td>23.0</td>\n",
       "      <td>/m/02vbb3r</td>\n",
       "      <td>/m/0bgchp9</td>\n",
       "      <td>/m/01y9xg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wiki ID Freebase ID Release date              Character name   Actor DOB   \n",
       "0   975900   /m/03vyhn   2001-08-24                    Akooshay  1958-08-26  \\\n",
       "1   975900   /m/03vyhn   2001-08-24  Lieutenant Melanie Ballard  1974-08-15   \n",
       "2   975900   /m/03vyhn   2001-08-24         Desolation Williams  1969-06-15   \n",
       "3   975900   /m/03vyhn   2001-08-24          Sgt Jericho Butler  1967-09-12   \n",
       "4   975900   /m/03vyhn   2001-08-24             Bashira Kincaid  1977-09-25   \n",
       "\n",
       "  Actor gender  Actor height Actor ethnicity          Actor name   \n",
       "0            F         1.620             NaN      Wanda De Jesus  \\\n",
       "1            F         1.780      /m/044038p  Natasha Henstridge   \n",
       "2            M         1.727         /m/0x67            Ice Cube   \n",
       "3            M         1.750             NaN       Jason Statham   \n",
       "4            F         1.650             NaN         Clea DuVall   \n",
       "\n",
       "   Actor age at release      Map ID Character ID    Actor ID  Role  \n",
       "0                  42.0  /m/0bgchxw   /m/0bgcj3x  /m/03wcfv7   NaN  \n",
       "1                  27.0   /m/0jys3m   /m/0bgchn4   /m/0346l4   NaN  \n",
       "2                  32.0   /m/0jys3g   /m/0bgchn_  /m/01vw26l   NaN  \n",
       "3                  33.0  /m/02vchl6   /m/0bgchnq   /m/034hyc   NaN  \n",
       "4                  23.0  /m/02vbb3r   /m/0bgchp9   /m/01y9xg   NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = RAW.character_data.copy()\n",
    "characters['Role'] = np.nan\n",
    "characters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will classify the characters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First version: characters who take up over 10% of all names are primary and the rest are secondary (many characters are classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "for index, row in sub_summaries.iterrows():\n",
    "    print(index)\n",
    "\n",
    "    # Wiki ID of the movie to consider\n",
    "    wiki_id = row['Wiki ID']\n",
    "\n",
    "    # Dictionary of the parsing results for this movie\n",
    "    parsing_result = row['Characters']\n",
    "\n",
    "    # All characters who belong to this movie\n",
    "    sub_characters = characters[characters['Wiki ID'] == wiki_id]\n",
    "    \n",
    "    # If the movie features actors inside of the character dataframe then proceed\n",
    "    if not(sub_characters.empty):\n",
    "        for i, r in sub_characters.iterrows():\n",
    "            # Take one of the characters\n",
    "            character = r['Character name']\n",
    "\n",
    "            # If the considered character has a valid name then proceed\n",
    "            if not(pd.isna(character)):\n",
    "                # Split the character in all of its words (name, surname, etc)\n",
    "                split_character_name = character.split()\n",
    "\n",
    "                count = 0\n",
    "                total = 0\n",
    "\n",
    "                for key, value in parsing_result.items():\n",
    "                    # Add all values to the total\n",
    "                    total += value\n",
    "\n",
    "                    for item in split_character_name:\n",
    "                        if item in key:\n",
    "                            # If we find a match then add to the count and stop (to avoid counting twice)\n",
    "                            count += value\n",
    "                            break\n",
    "                    \n",
    "                if total != 0:\n",
    "                    # Compute ratio\n",
    "                    ratio = count / total\n",
    "                else:\n",
    "                    # Empty dictionary: the character is a miss\n",
    "                    ratio = 0\n",
    "\n",
    "                if ratio > 0.1:\n",
    "                    # Primary character: appears 10% of the time or more\n",
    "                    characters.loc[(characters['Character name'] == character) & (characters['Wiki ID'] == wiki_id), 'Role'] = 'Primary'\n",
    "\n",
    "                elif ratio <= 0.1 and ratio > 0:\n",
    "                    # Secondary character: appears less than 10%\n",
    "                    characters.loc[(characters['Character name'] == character) & (characters['Wiki ID'] == wiki_id), 'Role'] = 'Secondary'\n",
    "\n",
    "                else:\n",
    "                    # None: The character was not mentioned in the summary\n",
    "                    characters.loc[(characters['Character name'] == character) & (characters['Wiki ID'] == wiki_id), 'Role'] = 'Missed'\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second version: the most common character is primary and the second most is secondary (only 2 characters are classified and there are no 'Missed' category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for index, row in sub_summaries.iterrows():\n",
    "    print(index)\n",
    "\n",
    "    # Wiki ID of the movie to consider\n",
    "    wiki_id = row['Wiki ID']\n",
    "\n",
    "    # Dictionary of the parsing results for this movie\n",
    "    parsing_result = row['Characters']\n",
    "\n",
    "    # All characters who belong to this movie\n",
    "    sub_characters = characters[characters['Wiki ID'] == wiki_id]\n",
    "\n",
    "    primary = None\n",
    "    secondary = None\n",
    "\n",
    "    most = -1\n",
    "    second_most = -1\n",
    "    \n",
    "    # If the movie features actors inside of the character dataframe then proceed\n",
    "    if not(sub_characters.empty):\n",
    "        for i, r in sub_characters.iterrows():\n",
    "            # Take one of the characters\n",
    "            character = r['Character name']\n",
    "\n",
    "            # If the considered character has a valid name then proceed\n",
    "            if not(pd.isna(character)):\n",
    "                # Split the character in all of its words (name, surname, etc)\n",
    "                split_character_name = character.split()\n",
    "\n",
    "                count = 0\n",
    "                total = 0\n",
    "\n",
    "                for key, value in parsing_result.items():\n",
    "                    # Add all values to the total\n",
    "                    total += value\n",
    "\n",
    "                    for item in split_character_name:\n",
    "                        if item in key:\n",
    "                            # If we find a match then add to the count and stop (to avoid counting twice)\n",
    "                            count += value\n",
    "                            break\n",
    "                    \n",
    "                if total != 0:\n",
    "                    # Compute ratio\n",
    "                    ratio = count / total\n",
    "                else:\n",
    "                    # Empty dictionary: the character is a miss\n",
    "                    ratio = 0\n",
    "\n",
    "                # Found a new character that appears more often than the current first\n",
    "                if ratio > most:\n",
    "                    # Current first becomes second\n",
    "                    second_most = most\n",
    "                    secondary = primary\n",
    "\n",
    "                    # New character gats first place\n",
    "                    most = ratio\n",
    "                    primary = character\n",
    "\n",
    "                else:\n",
    "                    # Found a new character that appears as often as the current first and there are still no second most\n",
    "                    if ratio == most and secondary == None:\n",
    "                        second_most = ratio\n",
    "                        secondary = character\n",
    "\n",
    "                    # Found a new character that appears less often than the current first and more often than the current second\n",
    "                    if ratio < most and ratio > second_most:\n",
    "                        second_most = ratio\n",
    "                        secondary = character\n",
    "\n",
    "    # Check that the primary and secondary characters are valid and assign the role if correct\n",
    "    # - if we couldn't classify both a primary and a secondary character then the movie is not useful\n",
    "    # - if the character name classified as primary matches with the most appearing name in the summary then it's good\n",
    "    # - same for secondary\n",
    "\n",
    "    keys = list(parsing_result.keys())\n",
    "    index = 0\n",
    "\n",
    "    assign_primary = False\n",
    "    assign_secondary = False\n",
    "    \n",
    "    if len(keys) >= 1 and primary != None:\n",
    "        if keys[index] in primary:\n",
    "            assign_primary = True\n",
    "\n",
    "        while keys[index] in primary and index < len(keys):\n",
    "            index += 1\n",
    "\n",
    "    if index < len(keys) and secondary != None:\n",
    "        if keys[index] in secondary:\n",
    "            assign_secondary = True\n",
    "\n",
    "    if assign_primary and assign_secondary:\n",
    "        characters.loc[(characters['Character name'] == primary) & (characters['Wiki ID'] == wiki_id), 'Role'] = 'Primary'\n",
    "        characters.loc[(characters['Character name'] == secondary) & (characters['Wiki ID'] == wiki_id), 'Role'] = 'Secondary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The characters who still have a NaN value inside of their `Role` column are characters who are not featured inside of their summaries, so they will not be useful. Therefore, we filter the characters who were assigned a role:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wiki ID</th>\n",
       "      <th>Freebase ID</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Character name</th>\n",
       "      <th>Actor DOB</th>\n",
       "      <th>Actor gender</th>\n",
       "      <th>Actor height</th>\n",
       "      <th>Actor ethnicity</th>\n",
       "      <th>Actor name</th>\n",
       "      <th>Actor age at release</th>\n",
       "      <th>Map ID</th>\n",
       "      <th>Character ID</th>\n",
       "      <th>Actor ID</th>\n",
       "      <th>Role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>20663735</td>\n",
       "      <td>/m/051zjwb</td>\n",
       "      <td>2000</td>\n",
       "      <td>M.K. Menon</td>\n",
       "      <td>1935-12-10</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/m/0dryh9k</td>\n",
       "      <td>Thilakan</td>\n",
       "      <td>64.0</td>\n",
       "      <td>/m/059t6pp</td>\n",
       "      <td>/m/0h73lnb</td>\n",
       "      <td>/m/02hkvw</td>\n",
       "      <td>Secondary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>20663735</td>\n",
       "      <td>/m/051zjwb</td>\n",
       "      <td>2000</td>\n",
       "      <td>Marancheri Induchoodan</td>\n",
       "      <td>1960-05-21</td>\n",
       "      <td>M</td>\n",
       "      <td>1.720</td>\n",
       "      <td>/m/0dryh9k</td>\n",
       "      <td>Mohanlal</td>\n",
       "      <td>39.0</td>\n",
       "      <td>/m/059t6p_</td>\n",
       "      <td>/m/0h8gtfl</td>\n",
       "      <td>/m/02fbpz</td>\n",
       "      <td>Primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107615</th>\n",
       "      <td>595909</td>\n",
       "      <td>/m/02tqm5</td>\n",
       "      <td>1988-11-03</td>\n",
       "      <td>Michael Chamberlain</td>\n",
       "      <td>1947-09-14</td>\n",
       "      <td>M</td>\n",
       "      <td>1.822</td>\n",
       "      <td>/m/02jvpv</td>\n",
       "      <td>Sam Neill</td>\n",
       "      <td>41.0</td>\n",
       "      <td>/m/02tbjj2</td>\n",
       "      <td>/m/0h2qv0j</td>\n",
       "      <td>/m/01ckhj</td>\n",
       "      <td>Secondary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107616</th>\n",
       "      <td>595909</td>\n",
       "      <td>/m/02tqm5</td>\n",
       "      <td>1988-11-03</td>\n",
       "      <td>Lindy Chamberlain</td>\n",
       "      <td>1949-06-22</td>\n",
       "      <td>F</td>\n",
       "      <td>1.680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meryl Streep</td>\n",
       "      <td>39.0</td>\n",
       "      <td>/m/02tb1h6</td>\n",
       "      <td>/m/05z0x_h</td>\n",
       "      <td>/m/0h0wc</td>\n",
       "      <td>Primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128473</th>\n",
       "      <td>2462689</td>\n",
       "      <td>/m/07ftxt</td>\n",
       "      <td>1941-05-03</td>\n",
       "      <td>Ann Mitchell</td>\n",
       "      <td>1907-07-16</td>\n",
       "      <td>F</td>\n",
       "      <td>1.650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barbara Stanwyck</td>\n",
       "      <td>33.0</td>\n",
       "      <td>/m/0k0kbm</td>\n",
       "      <td>/m/0h57bdz</td>\n",
       "      <td>/m/0bw6y</td>\n",
       "      <td>Secondary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128474</th>\n",
       "      <td>2462689</td>\n",
       "      <td>/m/07ftxt</td>\n",
       "      <td>1941-05-03</td>\n",
       "      <td>Long John Willoughby - 'John Doe'</td>\n",
       "      <td>1901-05-07</td>\n",
       "      <td>M</td>\n",
       "      <td>1.905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gary Cooper</td>\n",
       "      <td>39.0</td>\n",
       "      <td>/m/0k0kbg</td>\n",
       "      <td>/m/0h2svgl</td>\n",
       "      <td>/m/0c2tf</td>\n",
       "      <td>Primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363229</th>\n",
       "      <td>31186339</td>\n",
       "      <td>/m/0gkz15s</td>\n",
       "      <td>2012-03-12</td>\n",
       "      <td>Katniss Everdeen</td>\n",
       "      <td>1990-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jennifer Lawrence</td>\n",
       "      <td>21.0</td>\n",
       "      <td>/m/0gw7kv0</td>\n",
       "      <td>/m/0c01vfc</td>\n",
       "      <td>/m/02x0dzw</td>\n",
       "      <td>Primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363230</th>\n",
       "      <td>31186339</td>\n",
       "      <td>/m/0gkz15s</td>\n",
       "      <td>2012-03-12</td>\n",
       "      <td>Peeta Mellark</td>\n",
       "      <td>1992-10-12</td>\n",
       "      <td>M</td>\n",
       "      <td>1.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Josh Hutcherson</td>\n",
       "      <td>19.0</td>\n",
       "      <td>/m/0gw7kvp</td>\n",
       "      <td>/m/0c03gdc</td>\n",
       "      <td>/m/08wjf4</td>\n",
       "      <td>Secondary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Wiki ID Freebase ID Release date                     Character name   \n",
       "4633    20663735  /m/051zjwb         2000                         M.K. Menon  \\\n",
       "4639    20663735  /m/051zjwb         2000             Marancheri Induchoodan   \n",
       "107615    595909   /m/02tqm5   1988-11-03                Michael Chamberlain   \n",
       "107616    595909   /m/02tqm5   1988-11-03                  Lindy Chamberlain   \n",
       "128473   2462689   /m/07ftxt   1941-05-03                       Ann Mitchell   \n",
       "128474   2462689   /m/07ftxt   1941-05-03  Long John Willoughby - 'John Doe'   \n",
       "363229  31186339  /m/0gkz15s   2012-03-12                   Katniss Everdeen   \n",
       "363230  31186339  /m/0gkz15s   2012-03-12                      Peeta Mellark   \n",
       "\n",
       "         Actor DOB Actor gender  Actor height Actor ethnicity   \n",
       "4633    1935-12-10            M           NaN      /m/0dryh9k  \\\n",
       "4639    1960-05-21            M         1.720      /m/0dryh9k   \n",
       "107615  1947-09-14            M         1.822       /m/02jvpv   \n",
       "107616  1949-06-22            F         1.680             NaN   \n",
       "128473  1907-07-16            F         1.650             NaN   \n",
       "128474  1901-05-07            M         1.905             NaN   \n",
       "363229  1990-08-15            F         1.750             NaN   \n",
       "363230  1992-10-12            M         1.700             NaN   \n",
       "\n",
       "               Actor name  Actor age at release      Map ID Character ID   \n",
       "4633             Thilakan                  64.0  /m/059t6pp   /m/0h73lnb  \\\n",
       "4639             Mohanlal                  39.0  /m/059t6p_   /m/0h8gtfl   \n",
       "107615          Sam Neill                  41.0  /m/02tbjj2   /m/0h2qv0j   \n",
       "107616       Meryl Streep                  39.0  /m/02tb1h6   /m/05z0x_h   \n",
       "128473   Barbara Stanwyck                  33.0   /m/0k0kbm   /m/0h57bdz   \n",
       "128474        Gary Cooper                  39.0   /m/0k0kbg   /m/0h2svgl   \n",
       "363229  Jennifer Lawrence                  21.0  /m/0gw7kv0   /m/0c01vfc   \n",
       "363230    Josh Hutcherson                  19.0  /m/0gw7kvp   /m/0c03gdc   \n",
       "\n",
       "          Actor ID       Role  \n",
       "4633     /m/02hkvw  Secondary  \n",
       "4639     /m/02fbpz    Primary  \n",
       "107615   /m/01ckhj  Secondary  \n",
       "107616    /m/0h0wc    Primary  \n",
       "128473    /m/0bw6y  Secondary  \n",
       "128474    /m/0c2tf    Primary  \n",
       "363229  /m/02x0dzw    Primary  \n",
       "363230   /m/08wjf4  Secondary  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = characters[characters['Role'].notna()]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we store the result inside of a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('character_classification_15000_19999.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
